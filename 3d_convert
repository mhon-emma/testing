#!/usr/bin/env python3
"""
Fixed A2D2 converter for the actual JSON format used in your dataset
Based on your exact label3D structure
"""

import os
import json
import numpy as np
import cv2
from pathlib import Path
import shutil
from tqdm import tqdm
import yaml

class FixedA2D2Converter:
    def __init__(self):
        self.a2d2_root = Path("/home/Lambdaone/Emma/a2d2_full")
        self.bbox_root = self.a2d2_root / "camera_lidar_semantic_bboxes"
        self.output_root = Path("/home/Lambdaone/Emma/a2d2_yolo")
        
        # Camera matrix from your config
        self.camera_matrix = np.array([
            [1687.34, 0, 965.43],
            [0, 1783.43, 684.42],
            [0, 0, 1]
        ])
        
        # A2D2 classes from your data
        self.bbox_classes = ["Car", "VanSUV", "Truck", "Bus", "Pedestrian", "Bicycle", "TrafficSign", "TrafficLight"]
        
        # Setup output directories
        self.setup_output_directories()
    
    def setup_output_directories(self):
        """Setup output directories"""
        for task in ['2d_detection', '3d_detection']:
            for split in ['train', 'val', 'test']:
                (self.output_root / task / split / 'images').mkdir(parents=True, exist_ok=True)
                (self.output_root / task / split / 'labels').mkdir(parents=True, exist_ok=True)
                
                if task == '3d_detection':
                    (self.output_root / task / split / 'point_clouds').mkdir(parents=True, exist_ok=True)
        
        print(f"[OK] Output directories ready")
    
    def parse_a2d2_labels(self, label_file):
        """Parse your specific A2D2 label format"""
        try:
            with open(label_file, 'r') as f:
                data = json.load(f)
            
            # Your format: {"box_0": {...}, "box_1": {...}}
            objects = []
            
            for box_key, box_data in data.items():
                if box_key.startswith('box_') and isinstance(box_data, dict):
                    # Extract the data we need
                    obj = {
                        'class': box_data.get('class', 'unknown'),
                        'center': box_data.get('center', [0, 0, 0]),
                        'size': box_data.get('size', [1, 1, 1]),
                        'rot_angle': box_data.get('rot_angle', 0.0),
                        'alpha': box_data.get('alpha', 0.0),
                        '2d_bbox': box_data.get('2d_bbox', [0, 0, 0, 0]),
                        'occlusion': box_data.get('occlusion', 0.0),
                        'truncation': box_data.get('truncation', 0.0)
                    }
                    objects.append(obj)
            
            return objects
            
        except Exception as e:
            print(f"[ERROR] Parsing {label_file}: {e}")
            return []
    
    def convert_2d_bbox_to_yolo(self, bbox_2d, img_width, img_height):
        """Convert A2D2 2D bbox to YOLO format"""
        try:
            # A2D2 format: [x_min, y_min, x_max, y_max]
            x_min, y_min, x_max, y_max = bbox_2d
            
            # Convert to YOLO format (center, width, height, normalized)
            x_center = (x_min + x_max) / 2 / img_width
            y_center = (y_min + y_max) / 2 / img_height
            width = (x_max - x_min) / img_width
            height = (y_max - y_min) / img_height
            
            # Validate
            if 0 <= x_center <= 1 and 0 <= y_center <= 1 and 0 < width <= 1 and 0 < height <= 1:
                return [x_center, y_center, width, height]
            else:
                print(f"[WARNING] Invalid bbox: {bbox_2d} -> {[x_center, y_center, width, height]}")
                return None
                
        except Exception as e:
            print(f"[ERROR] Converting bbox {bbox_2d}: {e}")
            return None
    
    def file_already_processed(self, img_file, split_name, task):
        """Check if file already processed"""
        out_img = self.output_root / task / split_name / "images" / img_file.name
        out_label = self.output_root / task / split_name / "labels" / img_file.with_suffix('.txt').name
        return out_img.exists() and out_label.exists()
    
    def process_2d_detection(self):
        """Process 2D detection using the existing 2D bboxes in your data"""
        print("\n" + "="*50)
        print("PROCESSING 2D DETECTION (Fixed Format)")
        print("="*50)
        
        sequences = sorted(list(self.bbox_root.glob("2018*")), key=lambda x: x.name)
        
        if not sequences:
            print("[ERROR] No sequences found!")
            return
        
        print(f"Found {len(sequences)} sequences")
        
        # Split sequences
        n_total = len(sequences)
        n_train = int(n_total * 0.7)
        n_val = int(n_total * 0.15)
        
        splits = [
            (sequences[:n_train], "train"),
            (sequences[n_train:n_train+n_val], "val"),
            (sequences[n_train+n_val:], "test")
        ]
        
        total_processed = 0
        total_skipped = 0
        
        for seq_list, split_name in splits:
            if not seq_list:
                continue
            
            print(f"\nProcessing {split_name} split ({len(seq_list)} sequences)...")
            
            split_processed = 0
            split_skipped = 0
            
            for seq_dir in tqdm(seq_list, desc=split_name):
                camera_dir = seq_dir / "camera" / "cam_front_center"
                label3d_dir = seq_dir / "label3D" / "cam_front_center"
                
                if not (camera_dir.exists() and label3d_dir.exists()):
                    continue
                
                # Process each image
                for img_file in camera_dir.glob("*.png"):
                    # Find corresponding label3D file
                    base_name = img_file.stem
                    label_file = label3d_dir / f"{base_name.replace('camera', 'label3D')}.json"
                    
                    if not label_file.exists():
                        continue
                    
                    # Skip if already processed
                    if self.file_already_processed(img_file, split_name, "2d_detection"):
                        split_skipped += 1
                        continue
                    
                    try:
                        # Load image to get dimensions
                        img = cv2.imread(str(img_file))
                        if img is None:
                            continue
                        
                        h, w = img.shape[:2]
                        
                        # Parse A2D2 labels
                        objects = self.parse_a2d2_labels(label_file)
                        
                        if not objects:
                            continue
                        
                        # Convert to YOLO format
                        yolo_annotations = []
                        
                        for obj in objects:
                            class_name = obj['class']
                            
                            # Map class to ID
                            if class_name in self.bbox_classes:
                                class_id = self.bbox_classes.index(class_name)
                            else:
                                # Add unknown classes
                                if class_name not in self.bbox_classes:
                                    self.bbox_classes.append(class_name)
                                    class_id = len(self.bbox_classes) - 1
                                else:
                                    continue
                            
                            # Use the existing 2D bbox from A2D2
                            bbox_2d_a2d2 = obj['2d_bbox']
                            bbox_yolo = self.convert_2d_bbox_to_yolo(bbox_2d_a2d2, w, h)
                            
                            if bbox_yolo:
                                annotation = f"{class_id} {bbox_yolo[0]:.6f} {bbox_yolo[1]:.6f} {bbox_yolo[2]:.6f} {bbox_yolo[3]:.6f}"
                                yolo_annotations.append(annotation)
                        
                        # Save files
                        out_img = self.output_root / "2d_detection" / split_name / "images" / img_file.name
                        out_label = self.output_root / "2d_detection" / split_name / "labels" / img_file.with_suffix('.txt').name
                        
                        shutil.copy2(img_file, out_img)
                        
                        with open(out_label, 'w') as f:
                            f.write('\n'.join(yolo_annotations))
                        
                        split_processed += 1
                        
                    except Exception as e:
                        print(f"[ERROR] Processing {img_file.name}: {e}")
                        continue
            
            print(f"[OK] {split_name}: {split_processed} processed, {split_skipped} skipped")
            total_processed += split_processed
            total_skipped += split_skipped
        
        print(f"\n[FINAL] 2D Detection: {total_processed} processed, {total_skipped} skipped")
        print(f"[INFO] Found classes: {self.bbox_classes}")
    
    def process_3d_detection(self):
        """Process 3D detection using your format"""
        print("\n" + "="*50)
        print("PROCESSING 3D DETECTION (Fixed Format)")
        print("="*50)
        
        sequences = sorted(list(self.bbox_root.glob("2018*")), key=lambda x: x.name)
        
        # Split sequences
        n_total = len(sequences)
        n_train = int(n_total * 0.7)
        n_val = int(n_total * 0.15)
        
        splits = [
            (sequences[:n_train], "train"),
            (sequences[n_train:n_train+n_val], "val"),
            (sequences[n_train+n_val:], "test")
        ]
        
        total_processed = 0
        total_skipped = 0
        
        for seq_list, split_name in splits:
            if not seq_list:
                continue
            
            print(f"\nProcessing {split_name} split ({len(seq_list)} sequences)...")
            
            split_processed = 0
            split_skipped = 0
            
            for seq_dir in tqdm(seq_list, desc=split_name):
                camera_dir = seq_dir / "camera" / "cam_front_center"
                label3d_dir = seq_dir / "label3D" / "cam_front_center"
                lidar_dir = seq_dir / "lidar" / "cam_front_center"
                
                if not all([camera_dir.exists(), label3d_dir.exists(), lidar_dir.exists()]):
                    continue
                
                # Process each image
                for img_file in camera_dir.glob("*.png"):
                    base_name = img_file.stem
                    label_file = label3d_dir / f"{base_name.replace('camera', 'label3D')}.json"
                    lidar_file = lidar_dir / f"{base_name.replace('camera', 'lidar')}.npz"
                    
                    if not (label_file.exists() and lidar_file.exists()):
                        continue
                    
                    # Check if already processed
                    out_img = self.output_root / "3d_detection" / split_name / "images" / img_file.name
                    out_label = self.output_root / "3d_detection" / split_name / "labels" / img_file.with_suffix('.txt').name
                    out_lidar = self.output_root / "3d_detection" / split_name / "point_clouds" / lidar_file.name
                    
                    if all([out_img.exists(), out_label.exists(), out_lidar.exists()]):
                        split_skipped += 1
                        continue
                    
                    try:
                        # Parse A2D2 labels
                        objects = self.parse_a2d2_labels(label_file)
                        
                        if not objects:
                            continue
                        
                        # Convert to YOLO 3D format
                        yolo_3d_annotations = []
                        
                        for obj in objects:
                            class_name = obj['class']
                            
                            if class_name in self.bbox_classes:
                                class_id = self.bbox_classes.index(class_name)
                            else:
                                continue
                            
                            center = obj['center']
                            size = obj['size']
                            rotation = obj.get('rot_angle', 0.0)
                            
                            # Format: class_id x y z l w h rotation_y
                            annotation = f"{class_id} {center[0]:.6f} {center[1]:.6f} {center[2]:.6f} {size[0]:.6f} {size[1]:.6f} {size[2]:.6f} {rotation:.6f}"
                            yolo_3d_annotations.append(annotation)
                        
                        # Save files
                        shutil.copy2(img_file, out_img)
                        shutil.copy2(lidar_file, out_lidar)
                        
                        with open(out_label, 'w') as f:
                            f.write('\n'.join(yolo_3d_annotations))
                        
                        split_processed += 1
                        
                    except Exception as e:
                        print(f"[ERROR] Processing {img_file.name}: {e}")
                        continue
            
            print(f"[OK] {split_name}: {split_processed} processed, {split_skipped} skipped")
            total_processed += split_processed
            total_skipped += split_skipped
        
        print(f"\n[FINAL] 3D Detection: {total_processed} processed, {total_skipped} skipped")
    
    def create_configs(self):
        """Create dataset configuration files"""
        configs = {
            '2d_detection_config.yaml': {
                'path': str(self.output_root / '2d_detection'),
                'train': 'train/images',
                'val': 'val/images',
                'test': 'test/images',
                'nc': len(self.bbox_classes),
                'names': self.bbox_classes
            },
            '3d_detection_config.yaml': {
                'path': str(self.output_root / '3d_detection'),
                'train': 'train/images',
                'val': 'val/images',
                'test': 'test/images',
                'nc': len(self.bbox_classes),
                'names': self.bbox_classes,
                'format': '3d'
            }
        }
        
        for config_name, config_data in configs.items():
            config_path = self.output_root / config_name
            with open(config_path, 'w') as f:
                yaml.dump(config_data, f, default_flow_style=False)
            print(f"[OK] Created: {config_path}")
    
    def get_current_stats(self):
        """Get current dataset statistics"""
        stats = {}
        for task in ['2d_detection', '3d_detection']:
            stats[task] = {}
            total = 0
            for split in ['train', 'val', 'test']:
                img_dir = self.output_root / task / split / "images"
                count = len(list(img_dir.glob("*"))) if img_dir.exists() else 0
                stats[task][split] = count
                total += count
            stats[task]['total'] = total
        return stats
    
    def run_conversion(self):
        """Run the fixed conversion"""
        print("="*60)
        print("FIXED A2D2 CONVERTER")
        print("="*60)
        print(f"Input: {self.bbox_root}")
        print(f"Output: {self.output_root}")
        
        # Show current stats
        print("\nCurrent dataset status:")
        stats = self.get_current_stats()
        for task, task_stats in stats.items():
            print(f"{task}: {task_stats['total']} files")
        
        # Run conversion
        try:
            self.process_2d_detection()
            self.process_3d_detection()
            self.create_configs()
            
            print("\n" + "="*60)
            print("CONVERSION COMPLETED!")
            print("="*60)
            
            # Final stats
            final_stats = self.get_current_stats()
            for task, task_stats in final_stats.items():
                print(f"{task}: {task_stats['total']} files")
                print(f"  Train: {task_stats['train']}, Val: {task_stats['val']}, Test: {task_stats['test']}")
            
        except Exception as e:
            print(f"\n[ERROR] Conversion failed: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    converter = FixedA2D2Converter()
    converter.run_conversion()