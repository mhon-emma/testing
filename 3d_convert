#!/usr/bin/env python3
"""
Specific converter for A2D2 3D bounding box data
Based on your exact directory structure
"""

import os
import json
import numpy as np
import cv2
from pathlib import Path
import shutil
from tqdm import tqdm
import yaml

class A2D2BboxConverter:
    def __init__(self):
        self.a2d2_root = Path("/home/Lambdaone/Emma/a2d2_full")
        self.bbox_root = self.a2d2_root / "camera_lidar_semantic_bboxes"
        self.output_root = Path("/home/Lambdaone/Emma/a2d2_yolo")
        
        # Load camera matrix
        self.camera_matrix = np.array([
            [1687.34, 0, 965.43],
            [0, 1783.43, 684.42],
            [0, 0, 1]
        ])
        
        # Load 3D classes
        self.load_bbox_classes()
        
        # Setup output directories
        self.setup_output_directories()
    
    def load_bbox_classes(self):
        """Load 3D bbox class definitions"""
        class_file = self.bbox_root / "class_list.json"
        
        if class_file.exists():
            try:
                with open(class_file, 'r') as f:
                    classes_data = json.load(f)
                
                if isinstance(classes_data, dict):
                    self.bbox_classes = list(classes_data.keys())
                elif isinstance(classes_data, list):
                    self.bbox_classes = classes_data
                else:
                    self.bbox_classes = ["Car", "Pedestrian", "Bicycle", "Truck", "Bus"]
                    
                print(f"[OK] Loaded {len(self.bbox_classes)} bbox classes: {self.bbox_classes}")
                
            except Exception as e:
                print(f"[ERROR] Loading bbox classes: {e}")
                self.bbox_classes = ["Car", "Pedestrian", "Bicycle", "Truck", "Bus"]
        else:
            print("[WARNING] No bbox class file found, using defaults")
            self.bbox_classes = ["Car", "Pedestrian", "Bicycle", "Truck", "Bus"]
    
    def setup_output_directories(self):
        """Setup output directories"""
        for task in ['2d_detection', '3d_detection']:
            for split in ['train', 'val', 'test']:
                (self.output_root / task / split / 'images').mkdir(parents=True, exist_ok=True)
                (self.output_root / task / split / 'labels').mkdir(parents=True, exist_ok=True)
                
                if task == '3d_detection':
                    (self.output_root / task / split / 'point_clouds').mkdir(parents=True, exist_ok=True)
    
    def project_3d_to_2d_simple(self, center, size, img_width, img_height):
        """Simple 3D to 2D projection"""
        try:
            # Extract 3D center
            x_3d, y_3d, z_3d = center
            
            # Skip if behind camera
            if z_3d <= 0:
                return None
            
            # Project center point to 2D
            point_2d = self.camera_matrix @ np.array([x_3d, y_3d, z_3d])
            
            if point_2d[2] <= 0:
                return None
            
            x_2d = point_2d[0] / point_2d[2]
            y_2d = point_2d[1] / point_2d[2]
            
            # Check if within image bounds
            if x_2d < 0 or x_2d >= img_width or y_2d < 0 or y_2d >= img_height:
                return None
            
            # Estimate 2D box size from 3D size and distance
            length, width, height = size
            distance = z_3d
            
            # Simple projection of 3D size to 2D (rough estimate)
            focal_length = self.camera_matrix[0, 0]
            
            # Project 3D dimensions to 2D pixels
            box_width_2d = (width * focal_length) / distance
            box_height_2d = (height * focal_length) / distance
            
            # Ensure reasonable box size
            box_width_2d = max(10, min(box_width_2d, img_width / 2))
            box_height_2d = max(10, min(box_height_2d, img_height / 2))
            
            # Calculate box bounds
            x_min = max(0, x_2d - box_width_2d / 2)
            y_min = max(0, y_2d - box_height_2d / 2)
            x_max = min(img_width, x_2d + box_width_2d / 2)
            y_max = min(img_height, y_2d + box_height_2d / 2)
            
            # Convert to YOLO format (normalized)
            x_center = (x_min + x_max) / 2 / img_width
            y_center = (y_min + y_max) / 2 / img_height
            width_norm = (x_max - x_min) / img_width
            height_norm = (y_max - y_min) / img_height
            
            # Validate
            if 0 < width_norm < 1 and 0 < height_norm < 1:
                return [x_center, y_center, width_norm, height_norm]
            
        except Exception as e:
            print(f"[ERROR] Projection failed: {e}")
        
        return None
    
    def inspect_sequence_data(self):
        """Inspect what data we actually have"""
        print("Inspecting A2D2 bbox sequences...")
        
        sequences = list(self.bbox_root.glob("2018*"))
        print(f"Found {len(sequences)} sequences:")
        
        total_files = 0
        
        for seq in sequences:
            print(f"\nSequence: {seq.name}")
            
            # Check directories
            camera_dir = seq / "camera" / "cam_front_center"
            label3d_dir = seq / "label3D" / "cam_front_center"
            lidar_dir = seq / "lidar" / "cam_front_center"
            
            camera_files = list(camera_dir.glob("*.png")) if camera_dir.exists() else []
            label3d_files = list(label3d_dir.glob("*.json")) if label3d_dir.exists() else []
            lidar_files = list(lidar_dir.glob("*.npz")) if lidar_dir.exists() else []
            
            print(f"  Camera: {len(camera_files)} files")
            print(f"  Label3D: {len(label3d_files)} files") 
            print(f"  LiDAR: {len(lidar_files)} files")
            
            total_files += len(camera_files)
            
            # Check a sample label3D file
            if label3d_files:
                sample_label = label3d_files[0]
                try:
                    with open(sample_label, 'r') as f:
                        label_data = json.load(f)
                    
                    print(f"  Sample label: {len(label_data)} objects")
                    if label_data:
                        first_obj = label_data[0]
                        print(f"  Sample object keys: {list(first_obj.keys())}")
                        print(f"  Sample class: {first_obj.get('class', 'unknown')}")
                        
                except Exception as e:
                    print(f"  Error reading label: {e}")
        
        print(f"\nTotal images available: {total_files}")
        return sequences
    
    def process_2d_detection(self):
        """Process 2D detection from 3D bbox data"""
        print("\n" + "="*50)
        print("PROCESSING 2D DETECTION FROM 3D BBOXES")
        print("="*50)
        
        sequences = list(self.bbox_root.glob("2018*"))
        
        if not sequences:
            print("[ERROR] No sequences found!")
            return
        
        # Split sequences
        sequences = sorted(sequences, key=lambda x: x.name)
        n_total = len(sequences)
        n_train = int(n_total * 0.7)
        n_val = int(n_total * 0.15)
        
        splits = [
            (sequences[:n_train], "train"),
            (sequences[n_train:n_train+n_val], "val"),
            (sequences[n_train+n_val:], "test")
        ]
        
        total_processed = 0
        
        for seq_list, split_name in splits:
            if not seq_list:
                continue
            
            print(f"\nProcessing {split_name} split ({len(seq_list)} sequences)...")
            
            split_processed = 0
            
            for seq_dir in tqdm(seq_list, desc=split_name):
                camera_dir = seq_dir / "camera" / "cam_front_center"
                label3d_dir = seq_dir / "label3D" / "cam_front_center"
                
                if not (camera_dir.exists() and label3d_dir.exists()):
                    print(f"[SKIP] {seq_dir.name}: Missing directories")
                    continue
                
                # Process each image
                for img_file in camera_dir.glob("*.png"):
                    # Find corresponding 3D label
                    base_name = img_file.stem
                    label_file = label3d_dir / f"{base_name.replace('camera', 'label3D')}.json"
                    
                    if not label_file.exists():
                        continue
                    
                    # Check if already processed
                    out_img = self.output_root / "2d_detection" / split_name / "images" / img_file.name
                    out_label = self.output_root / "2d_detection" / split_name / "labels" / img_file.with_suffix('.txt').name
                    
                    if out_img.exists() and out_label.exists():
                        continue
                    
                    try:
                        # Load image
                        img = cv2.imread(str(img_file))
                        if img is None:
                            continue
                        
                        h, w = img.shape[:2]
                        
                        # Load 3D annotations
                        with open(label_file, 'r') as f:
                            bbox_data = json.load(f)
                        
                        # Convert 3D bboxes to 2D
                        yolo_annotations = []
                        
                        for bbox_3d in bbox_data:
                            class_name = bbox_3d.get('class', 'unknown')
                            
                            # Map class to ID
                            if class_name in self.bbox_classes:
                                class_id = self.bbox_classes.index(class_name)
                            else:
                                continue
                            
                            # Get 3D bbox parameters
                            center = bbox_3d.get('center', [0, 0, 0])
                            size = bbox_3d.get('size', [1, 1, 1])
                            
                            # Convert to 2D
                            bbox_2d = self.project_3d_to_2d_simple(center, size, w, h)
                            
                            if bbox_2d:
                                annotation = f"{class_id} {bbox_2d[0]:.6f} {bbox_2d[1]:.6f} {bbox_2d[2]:.6f} {bbox_2d[3]:.6f}"
                                yolo_annotations.append(annotation)
                        
                        # Save files
                        shutil.copy2(img_file, out_img)
                        
                        with open(out_label, 'w') as f:
                            f.write('\n'.join(yolo_annotations))
                        
                        split_processed += 1
                        
                    except Exception as e:
                        print(f"[ERROR] Processing {img_file.name}: {e}")
                        continue
            
            print(f"[OK] {split_name}: {split_processed} files processed")
            total_processed += split_processed
        
        print(f"\n[FINAL] 2D Detection: {total_processed} files processed")
    
    def process_3d_detection(self):
        """Process 3D detection data"""
        print("\n" + "="*50)
        print("PROCESSING 3D DETECTION")
        print("="*50)
        
        sequences = list(self.bbox_root.glob("2018*"))
        
        # Split sequences
        sequences = sorted(sequences, key=lambda x: x.name)
        n_total = len(sequences)
        n_train = int(n_total * 0.7)
        n_val = int(n_total * 0.15)
        
        splits = [
            (sequences[:n_train], "train"),
            (sequences[n_train:n_train+n_val], "val"),
            (sequences[n_train+n_val:], "test")
        ]
        
        total_processed = 0
        
        for seq_list, split_name in splits:
            if not seq_list:
                continue
            
            print(f"\nProcessing {split_name} split ({len(seq_list)} sequences)...")
            
            split_processed = 0
            
            for seq_dir in tqdm(seq_list, desc=split_name):
                camera_dir = seq_dir / "camera" / "cam_front_center"
                label3d_dir = seq_dir / "label3D" / "cam_front_center"
                lidar_dir = seq_dir / "lidar" / "cam_front_center"
                
                if not all([camera_dir.exists(), label3d_dir.exists(), lidar_dir.exists()]):
                    continue
                
                # Process each image
                for img_file in camera_dir.glob("*.png"):
                    base_name = img_file.stem
                    label_file = label3d_dir / f"{base_name.replace('camera', 'label3D')}.json"
                    lidar_file = lidar_dir / f"{base_name.replace('camera', 'lidar')}.npz"
                    
                    if not (label_file.exists() and lidar_file.exists()):
                        continue
                    
                    # Check if already processed
                    out_img = self.output_root / "3d_detection" / split_name / "images" / img_file.name
                    out_label = self.output_root / "3d_detection" / split_name / "labels" / img_file.with_suffix('.txt').name
                    out_lidar = self.output_root / "3d_detection" / split_name / "point_clouds" / lidar_file.name
                    
                    if all([out_img.exists(), out_label.exists(), out_lidar.exists()]):
                        continue
                    
                    try:
                        # Load 3D annotations
                        with open(label_file, 'r') as f:
                            bbox_data = json.load(f)
                        
                        # Process 3D annotations
                        yolo_3d_annotations = []
                        
                        for bbox_3d in bbox_data:
                            class_name = bbox_3d.get('class', 'unknown')
                            
                            if class_name in self.bbox_classes:
                                class_id = self.bbox_classes.index(class_name)
                            else:
                                continue
                            
                            center = bbox_3d.get('center', [0, 0, 0])
                            size = bbox_3d.get('size', [1, 1, 1])
                            rotation = bbox_3d.get('rotation', [0, 0, 0])
                            
                            # Format: class_id x y z l w h rotation_y
                            annotation = f"{class_id} {center[0]:.6f} {center[1]:.6f} {center[2]:.6f} {size[0]:.6f} {size[1]:.6f} {size[2]:.6f} {rotation[2]:.6f}"
                            yolo_3d_annotations.append(annotation)
                        
                        # Save files
                        shutil.copy2(img_file, out_img)
                        shutil.copy2(lidar_file, out_lidar)
                        
                        with open(out_label, 'w') as f:
                            f.write('\n'.join(yolo_3d_annotations))
                        
                        split_processed += 1
                        
                    except Exception as e:
                        print(f"[ERROR] Processing {img_file.name}: {e}")
                        continue
            
            print(f"[OK] {split_name}: {split_processed} files processed")
            total_processed += split_processed
        
        print(f"\n[FINAL] 3D Detection: {total_processed} files processed")
    
    def create_configs(self):
        """Create dataset configuration files"""
        configs = {
            '2d_detection_config.yaml': {
                'path': str(self.output_root / '2d_detection'),
                'train': 'train/images',
                'val': 'val/images',
                'test': 'test/images',
                'nc': len(self.bbox_classes),
                'names': self.bbox_classes
            },
            '3d_detection_config.yaml': {
                'path': str(self.output_root / '3d_detection'),
                'train': 'train/images',
                'val': 'val/images',
                'test': 'test/images',
                'nc': len(self.bbox_classes),
                'names': self.bbox_classes,
                'format': '3d'
            }
        }
        
        for config_name, config_data in configs.items():
            config_path = self.output_root / config_name
            with open(config_path, 'w') as f:
                yaml.dump(config_data, f, default_flow_style=False)
            print(f"[OK] Created: {config_path}")
    
    def run_conversion(self):
        """Run the bbox-specific conversion"""
        print("="*60)
        print("A2D2 BBOX SPECIFIC CONVERTER")
        print("="*60)
        
        # Inspect data first
        sequences = self.inspect_sequence_data()
        
        print(f"\nStarting conversion...")
        
        # Process both tasks
        self.process_2d_detection()
        self.process_3d_detection()
        
        # Create configs
        self.create_configs()
        
        print("\n" + "="*60)
        print("BBOX CONVERSION COMPLETED!")
        print("="*60)

if __name__ == "__main__":
    converter = A2D2BboxConverter()
    converter.run_conversion()