import json
import os
import numpy as np
from pathlib import Path
import cv2
from typing import Dict, List, Tuple

class A2D2Converter:
    def __init__(self, a2d2_root_path: str):
        self.root_path = Path(a2d2_root_path)
        self.bbox_path = self.root_path / "camera_lidar_semantic_bboxes"
        
        # Load class list from the semantic dataset
        semantic_class_file = self.root_path / "camera_lidar_semantic" / "class_list.json"
        bbox_class_file = self.bbox_path / "class_list.json"
        
        # Use whichever class file exists
        if bbox_class_file.exists():
            with open(bbox_class_file, 'r') as f:
                self.class_list = json.load(f)
        elif semantic_class_file.exists():
            with open(semantic_class_file, 'r') as f:
                self.class_list = json.load(f)
        else:
            # Default classes based on A2D2 documentation
            self.class_list = {
                "Car": "Car",
                "VanSUV": "VanSUV", 
                "Truck": "Truck",
                "Pedestrian": "Pedestrian",
                "Bicycle": "Bicycle",
                "MotorBike": "MotorBike",
                "Bus": "Bus"
            }
        
        # Load camera configuration
        config_file = self.root_path / "cams_lidars.json"
        if config_file.exists():
            with open(config_file, 'r') as f:
                self.config = json.load(f)
        else:
            self.config = None
            print("Warning: cams_lidars.json not found. Will use image dimensions from files.")
    
    def project_3d_to_2d(self, points_3d: np.ndarray, camera_name: str) -> Tuple[np.ndarray, np.ndarray]:
        """Project 3D points to 2D using camera intrinsics"""
        if self.config is None:
            print("Warning: No camera config available")
            return np.array([]), np.array([])
            
        # Get camera intrinsic matrix (undistorted)
        cam_matrix = np.array(self.config['cameras'][camera_name]['CamMatrix'])
        
        # Filter out points behind the camera (z > 0 in camera coordinates)
        valid_mask = points_3d[:, 2] > 0
        valid_points = points_3d[valid_mask]
        
        if len(valid_points) == 0:
            return np.array([]), valid_mask
        
        # Project to 2D
        points_2d_homogeneous = cam_matrix @ valid_points.T
        points_2d = (points_2d_homogeneous[:2] / points_2d_homogeneous[2]).T
        
        return points_2d, valid_mask
    
    def extract_2d_bbox_from_3d_points(self, points_3d: List, camera_name: str, img_width: int, img_height: int) -> List:
        """Extract 2D bounding box from 3D corner points"""
        if not points_3d or len(points_3d) != 8:
            return []
            
        # Convert to numpy array
        corners_3d = np.array(points_3d)
        
        # Project to 2D
        corners_2d, valid_mask = self.project_3d_to_2d(corners_3d, camera_name)
        
        if len(corners_2d) == 0:
            return []
        
        # Get bounding box from projected corners
        x_coords = corners_2d[:, 0]
        y_coords = corners_2d[:, 1]
        
        x_min, x_max = np.min(x_coords), np.max(x_coords)
        y_min, y_max = np.min(y_coords), np.max(y_coords)
        
        # Clamp to image bounds
        x_min = max(0, min(x_min, img_width))
        x_max = max(0, min(x_max, img_width))
        y_min = max(0, min(y_min, img_height))
        y_max = max(0, min(y_max, img_height))
        
        # Only return valid bounding boxes
        if x_max > x_min and y_max > y_min:
            return [x_min, y_min, x_max - x_min, y_max - y_min]  # [x, y, width, height]
        
        return []
    
    def process_3d_labels(self, label3d_file: str, camera_name: str, img_width: int, img_height: int) -> List[Dict]:
        """Process 3D bounding box labels from A2D2 format"""
        try:
            with open(label3d_file, 'r') as f:
                label3d_data = json.load(f)
        except:
            return []
        
        annotations = []
        
        # Process each bounding box in the file
        for box_key, box_data in label3d_data.items():
            if not box_key.startswith('box_'):
                continue
                
            # Get class name
            class_name = box_data.get('class', 'Unknown')
            
            # Method 1: Use provided 2d_bbox if available and valid
            if '2d_bbox' in box_data and len(box_data['2d_bbox']) == 4:
                x_min, y_min, x_max, y_max = box_data['2d_bbox']
                bbox_2d = [x_min, y_min, x_max - x_min, y_max - y_min]
            
            # Method 2: Project 3D points to 2D if 3d_points available
            elif '3d_points' in box_data:
                bbox_2d = self.extract_2d_bbox_from_3d_points(
                    box_data['3d_points'], camera_name, img_width, img_height
                )
            
            # Method 3: Use center and size to estimate 3D corners, then project
            elif 'center' in box_data and 'size' in box_data:
                center = np.array(box_data['center'])
                size = np.array(box_data['size'])
                
                # Create 8 corners of 3D box
                half_size = size / 2
                corners_3d = np.array([
                    center + [-half_size[0], -half_size[1], -half_size[2]],
                    center + [+half_size[0], -half_size[1], -half_size[2]],
                    center + [+half_size[0], +half_size[1], -half_size[2]],
                    center + [-half_size[0], +half_size[1], -half_size[2]],
                    center + [-half_size[0], -half_size[1], +half_size[2]],
                    center + [+half_size[0], -half_size[1], +half_size[2]],
                    center + [+half_size[0], +half_size[1], +half_size[2]],
                    center + [-half_size[0], +half_size[1], +half_size[2]],
                ])
                
                # Apply rotation if available
                if 'axis' in box_data and 'rot_angle' in box_data:
                    axis = np.array(box_data['axis'])
                    angle = box_data['rot_angle']
                    
                    # Create rotation matrix from axis-angle
                    if np.linalg.norm(axis) > 0:
                        axis = axis / np.linalg.norm(axis)
                        cos_angle = np.cos(angle)
                        sin_angle = np.sin(angle)
                        
                        # Rodrigues' rotation formula
                        rotation_matrix = (cos_angle * np.eye(3) + 
                                         sin_angle * self._skew_symmetric(axis) +
                                         (1 - cos_angle) * np.outer(axis, axis))
                        
                        # Apply rotation to each corner
                        corners_3d = (rotation_matrix @ (corners_3d - center).T).T + center
                
                # Project to 2D
                corners_2d, valid_mask = self.project_3d_to_2d(corners_3d, camera_name)
                
                if len(corners_2d) > 0:
                    x_coords = corners_2d[:, 0]
                    y_coords = corners_2d[:, 1]
                    
                    x_min, x_max = np.min(x_coords), np.max(x_coords)
                    y_min, y_max = np.min(y_coords), np.max(y_coords)
                    
                    # Clamp to image bounds
                    x_min = max(0, min(x_min, img_width))
                    x_max = max(0, min(x_max, img_width))
                    y_min = max(0, min(y_min, img_height))
                    y_max = max(0, min(y_max, img_height))
                    
                    if x_max > x_min and y_max > y_min:
                        bbox_2d = [x_min, y_min, x_max - x_min, y_max - y_min]
                    else:
                        bbox_2d = []
                else:
                    bbox_2d = []
            else:
                bbox_2d = []
            
            # Add annotation if valid bounding box
            if bbox_2d and len(bbox_2d) == 4:
                annotations.append({
                    'class': class_name,
                    'bbox': bbox_2d,
                    'bbox_coords': [bbox_2d[0], bbox_2d[1], 
                                  bbox_2d[0] + bbox_2d[2], bbox_2d[1] + bbox_2d[3]],
                    'id': box_data.get('id', 0),
                    'truncation': box_data.get('truncation', 0.0),
                    'occlusion': box_data.get('occlusion', 0.0)
                })
        
        return annotations
    
    def _skew_symmetric(self, v):
        """Create skew symmetric matrix from vector"""
        return np.array([[0, -v[2], v[1]], 
                        [v[2], 0, -v[0]], 
                        [-v[1], v[0], 0]])
    
    def get_unique_classes(self) -> List[str]:
        """Get all unique class names from the dataset"""
        classes = set()
        
        # Process each sequence
        for sequence_dir in self.bbox_path.iterdir():
            if not sequence_dir.is_dir() or sequence_dir.name.startswith('.'):
                continue
            
            label3d_dir = sequence_dir / "label3D" / "cam_front_center"
            if not label3d_dir.exists():
                continue
            
            # Process each label file
            for label_file in label3d_dir.glob("*.json"):
                try:
                    with open(label_file, 'r') as f:
                        label_data = json.load(f)
                    
                    for box_key, box_data in label_data.items():
                        if box_key.startswith('box_') and 'class' in box_data:
                            classes.add(box_data['class'])
                except:
                    continue
        
        return sorted(list(classes))
    
    def convert_to_coco_format(self, output_file: str):
        """Convert A2D2 to COCO format"""
        coco_data = {
            "images": [],
            "annotations": [],
            "categories": []
        }
        
        # Get unique classes from the dataset
        unique_classes = self.get_unique_classes()
        print(f"Found classes: {unique_classes}")
        
        # Create categories
        category_map = {}
        for idx, class_name in enumerate(unique_classes):
            category_id = idx + 1
            coco_data["categories"].append({
                "id": category_id,
                "name": class_name,
                "supercategory": "object"
            })
            category_map[class_name] = category_id
        
        image_id = 0
        annotation_id = 0
        
        # Process each sequence
        for sequence_dir in self.bbox_path.iterdir():
            if not sequence_dir.is_dir() or sequence_dir.name.startswith('.'):
                continue
            
            print(f"Processing sequence: {sequence_dir.name}")
            
            camera_dir = sequence_dir / "camera" / "cam_front_center"
            label3d_dir = sequence_dir / "label3D" / "cam_front_center"
            
            if not camera_dir.exists() or not label3d_dir.exists():
                continue
            
            # Process each image in the sequence
            for img_file in camera_dir.glob("*.png"):
                image_id += 1
                
                # Get corresponding JSON files
                base_name = img_file.stem
                camera_json = camera_dir / f"{base_name}.json"
                label3d_json = label3d_dir / f"{base_name}.json"
                
                if not label3d_json.exists():
                    continue
                
                # Load image to get dimensions
                try:
                    img = cv2.imread(str(img_file))
                    if img is None:
                        continue
                    height, width = img.shape[:2]
                except:
                    continue
                
                # Add image info
                coco_data["images"].append({
                    "id": image_id,
                    "file_name": f"{sequence_dir.name}_{img_file.name}",
                    "width": width,
                    "height": height,
                    "sequence": sequence_dir.name
                })
                
                # Process 3D labels
                annotations = self.process_3d_labels(str(label3d_json), "front_center", width, height)
                
                for ann in annotations:
                    if ann['class'] in category_map:
                        annotation_id += 1
                        x, y, w, h = ann['bbox']
                        
                        coco_data["annotations"].append({
                            "id": annotation_id,
                            "image_id": image_id,
                            "category_id": category_map[ann['class']],
                            "bbox": [x, y, w, h],
                            "area": w * h,
                            "iscrowd": 0,
                            "truncation": ann.get('truncation', 0.0),
                            "occlusion": ann.get('occlusion', 0.0)
                        })
        
        # Save COCO format
        with open(output_file, 'w') as f:
            json.dump(coco_data, f, indent=2)
        
        print(f"\nCOCO format saved to {output_file}")
        print(f"Total images: {len(coco_data['images'])}")
        print(f"Total annotations: {len(coco_data['annotations'])}")
        print(f"Categories: {[cat['name'] for cat in coco_data['categories']]}")
    
    def convert_to_yolo_format(self, output_dir: str):
        """Convert A2D2 to YOLO format"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # Get unique classes from the dataset
        unique_classes = self.get_unique_classes()
        print(f"Found classes: {unique_classes}")
        
        # Create class names file
        with open(output_path / "classes.txt", 'w') as f:
            for class_name in unique_classes:
                f.write(f"{class_name}\n")
        
        # Create class mapping
        class_to_id = {name: idx for idx, name in enumerate(unique_classes)}
        
        image_count = 0
        annotation_count = 0
        
        # Process each sequence
        for sequence_dir in self.bbox_path.iterdir():
            if not sequence_dir.is_dir() or sequence_dir.name.startswith('.'):
                continue
            
            print(f"Processing sequence: {sequence_dir.name}")
            
            camera_dir = sequence_dir / "camera" / "cam_front_center"
            label3d_dir = sequence_dir / "label3D" / "cam_front_center"
            
            if not camera_dir.exists() or not label3d_dir.exists():
                continue
            
            # Process each image in the sequence
            for img_file in camera_dir.glob("*.png"):
                base_name = img_file.stem
                label3d_json = label3d_dir / f"{base_name}.json"
                
                if not label3d_json.exists():
                    continue
                
                # Load image dimensions
                try:
                    img = cv2.imread(str(img_file))
                    if img is None:
                        continue
                    img_height, img_width = img.shape[:2]
                except:
                    continue
                
                # Process 3D labels
                annotations = self.process_3d_labels(str(label3d_json), "front_center", img_width, img_height)
                
                # Create YOLO annotation file
                yolo_file = output_path / f"{sequence_dir.name}_{base_name}.txt"
                
                with open(yolo_file, 'w') as f:
                    for ann in annotations:
                        if ann['class'] in class_to_id:
                            class_id = class_to_id[ann['class']]
                            x_min, y_min, x_max, y_max = ann['bbox_coords']
                            
                            # Convert to YOLO format (normalized center coordinates)
                            center_x = (x_min + x_max) / 2 / img_width
                            center_y = (y_min + y_max) / 2 / img_height
                            width = (x_max - x_min) / img_width
                            height = (y_max - y_min) / img_height
                            
                            f.write(f"{class_id} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\n")
                            annotation_count += 1
                
                image_count += 1
        
        print(f"\nYOLO format saved to {output_dir}")
        print(f"Total images: {image_count}")
        print(f"Total annotations: {annotation_count}")
        print(f"Classes file: {output_path / 'classes.txt'}")
        print(f"Categories: {unique_classes}")

# Usage example
if __name__ == "__main__":
    # Initialize converter with your A2D2 dataset path
    converter = A2D2Converter("/path/to/your/a2d2/dataset")
    
    # Convert to COCO format
    converter.convert_to_coco_format("a2d2_coco.json")
    
    # Convert to YOLO format
    converter.convert_to_yolo_format("a2d2_yolo")