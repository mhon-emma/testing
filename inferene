#include <iostream>
#include <fstream>
#include <vector>
#include <string>
#include <memory>
#include <NvInfer.h>
#include <NvInferRuntime.h>
#include <opencv2/opencv.hpp>

// ============================================
// CHANGE THESE PATHS FOR YOUR FILES
// ============================================
const std::string ENGINE_PATH = "yolov12x.plan";           // Your .plan file
const std::string IMAGE_PATH = "test_image.jpg";           // Your test image (optional)
// ============================================

class Logger : public nvinfer1::ILogger {
public:
    void log(Severity severity, const char* msg) noexcept override {
        if (severity <= Severity::kWARNING) {
            std::cout << "[TensorRT] " << msg << std::endl;
        }
    }
};

class YOLOValidator {
private:
    std::unique_ptr<nvinfer1::IRuntime> runtime;
    std::unique_ptr<nvinfer1::ICudaEngine> engine;
    std::unique_ptr<nvinfer1::IExecutionContext> context;
    Logger logger;

public:
    YOLOValidator() {
        runtime = std::unique_ptr<nvinfer1::IRuntime>(nvinfer1::createInferRuntime(logger));
    }
    
    bool loadEngine(const std::string& enginePath) {
        std::ifstream file(enginePath, std::ios::binary);
        if (!file.good()) {
            std::cerr << "ERROR: Cannot open engine file: " << enginePath << std::endl;
            return false;
        }
        
        // Read engine file
        file.seekg(0, std::ios::end);
        size_t size = file.tellg();
        file.seekg(0, std::ios::beg);
        
        std::vector<char> engineData(size);
        file.read(engineData.data(), size);
        file.close();
        
        // Create engine
        engine = std::unique_ptr<nvinfer1::ICudaEngine>(
            runtime->deserializeCudaEngine(engineData.data(), size));
        
        if (!engine) {
            std::cerr << "ERROR: Failed to create engine" << std::endl;
            return false;
        }
        
        context = std::unique_ptr<nvinfer1::IExecutionContext>(engine->createExecutionContext());
        if (!context) {
            std::cerr << "ERROR: Failed to create context" << std::endl;
            return false;
        }
        
        std::cout << "SUCCESS: Engine loaded successfully: " << enginePath << std::endl;
        return true;
    }
    
    void analyzeEngine() {
        if (!engine) return;
        
        std::cout << "\n=== ENGINE INFO ===" << std::endl;
        int nbBindings = engine->getNbBindings();
        std::cout << "Bindings: " << nbBindings << std::endl;
        std::cout << "Memory needed: " << (engine->getDeviceMemorySize() / 1024 / 1024) << " MB" << std::endl;
        std::cout << "Implicit batch: " << (engine->hasImplicitBatchDimension() ? "Yes" : "No") << std::endl;
        
        // Show each input/output
        for (int i = 0; i < nbBindings; i++) {
            const char* name = engine->getBindingName(i);
            nvinfer1::Dims dims = engine->getBindingDimensions(i);
            bool isInput = engine->bindingIsInput(i);
            
            std::cout << "\n[" << i << "] " << name << " (" << (isInput ? "INPUT" : "OUTPUT") << ")" << std::endl;
            std::cout << "    Shape: ";
            for (int j = 0; j < dims.nbDims; j++) {
                std::cout << dims.d[j];
                if (j < dims.nbDims - 1) std::cout << "x";
            }
            std::cout << std::endl;
            
            // Calculate memory size
            size_t elements = 1;
            for (int j = 0; j < dims.nbDims; j++) {
                if (dims.d[j] > 0) elements *= dims.d[j];
            }
            size_t bytes = elements * 4; // Assuming float32
            std::cout << "    Memory: " << bytes << " bytes";
            if (bytes > 1024 * 1024) {
                std::cout << " (" << (bytes / 1024 / 1024) << " MB)";
            }
            std::cout << std::endl;
        }
    }
    
    void checkImage(const std::string& imagePath) {
        if (!engine) return;
        
        cv::Mat image = cv::imread(imagePath);
        if (image.empty()) {
            std::cout << "WARNING: Cannot load image: " << imagePath << " (skipping image check)" << std::endl;
            return;
        }
        
        std::cout << "\n=== IMAGE CHECK ===" << std::endl;
        std::cout << "Image: " << image.cols << "x" << image.rows << " (channels: " << image.channels() << ")" << std::endl;
        
        // Find input binding
        int inputIndex = -1;
        nvinfer1::Dims inputDims;
        for (int i = 0; i < engine->getNbBindings(); i++) {
            if (engine->bindingIsInput(i)) {
                inputIndex = i;
                inputDims = engine->getBindingDimensions(i);
                break;
            }
        }
        
        if (inputIndex == -1) {
            std::cout << "ERROR: No input found!" << std::endl;
            return;
        }
        
        // Get required dimensions
        int reqChannels, reqHeight, reqWidth;
        if (engine->hasImplicitBatchDimension() && inputDims.nbDims == 3) {
            // CHW format
            reqChannels = inputDims.d[0];
            reqHeight = inputDims.d[1];
            reqWidth = inputDims.d[2];
        } else if (!engine->hasImplicitBatchDimension() && inputDims.nbDims == 4) {
            // NCHW format
            reqChannels = inputDims.d[1];
            reqHeight = inputDims.d[2];
            reqWidth = inputDims.d[3];
        } else {
            std::cout << "ERROR: Unexpected input format!" << std::endl;
            return;
        }
        
        std::cout << "Required: " << reqWidth << "x" << reqHeight << " (channels: " << reqChannels << ")" << std::endl;
        
        // Check compatibility
        if (image.channels() != reqChannels) {
            std::cout << "WARNING: Channel mismatch! Need to convert " << image.channels() << " -> " << reqChannels << std::endl;
        } else {
            std::cout << "OK: Channels match" << std::endl;
        }
        
        // Calculate padding for letterbox
        float scale = std::min((float)reqWidth / image.cols, (float)reqHeight / image.rows);
        int newWidth = (int)(image.cols * scale);
        int newHeight = (int)(image.rows * scale);
        int padLeft = (reqWidth - newWidth) / 2;
        int padTop = (reqHeight - newHeight) / 2;
        int padRight = reqWidth - newWidth - padLeft;
        int padBottom = reqHeight - newHeight - padTop;
        
        std::cout << "\n=== PREPROCESSING ===" << std::endl;
        std::cout << "1. Resize to: " << newWidth << "x" << newHeight << " (scale: " << scale << ")" << std::endl;
        std::cout << "2. Pad: L=" << padLeft << " T=" << padTop << " R=" << padRight << " B=" << padBottom << std::endl;
        std::cout << "3. Convert to float32 and normalize (/255.0)" << std::endl;
        std::cout << "4. Convert HWC -> " << (engine->hasImplicitBatchDimension() ? "CHW" : "NCHW") << std::endl;
        
        // Show OpenCV code
        std::cout << "\n=== OPENCV CODE ===" << std::endl;
        std::cout << "cv::Mat resized, padded, floatImg;" << std::endl;
        std::cout << "cv::resize(image, resized, cv::Size(" << newWidth << ", " << newHeight << "));" << std::endl;
        if (padLeft > 0 || padTop > 0 || padRight > 0 || padBottom > 0) {
            std::cout << "cv::copyMakeBorder(resized, padded, " << padTop << ", " << padBottom;
            std::cout << ", " << padLeft << ", " << padRight << ", cv::BORDER_CONSTANT, cv::Scalar(114, 114, 114));" << std::endl;
            std::cout << "padded.convertTo(floatImg, CV_32F, 1.0/255.0);" << std::endl;
        } else {
            std::cout << "resized.convertTo(floatImg, CV_32F, 1.0/255.0);" << std::endl;
        }
    }
    
    void showInferenceCode() {
        if (!engine) return;
        
        std::cout << "\n=== INFERENCE CODE ===" << std::endl;
        
        // Memory allocation
        std::cout << "// 1. Allocate GPU memory" << std::endl;
        std::cout << "void* buffers[" << engine->getNbBindings() << "];" << std::endl;
        for (int i = 0; i < engine->getNbBindings(); i++) {
            nvinfer1::Dims dims = engine->getBindingDimensions(i);
            size_t elements = 1;
            for (int j = 0; j < dims.nbDims; j++) {
                if (dims.d[j] > 0) elements *= dims.d[j];
            }
            size_t bytes = elements * 4;
            std::cout << "cudaMalloc(&buffers[" << i << "], " << bytes << "); // " << engine->getBindingName(i) << std::endl;
        }
        
        // Copy input
        std::cout << "\n// 2. Copy input data to GPU" << std::endl;
        for (int i = 0; i < engine->getNbBindings(); i++) {
            if (engine->bindingIsInput(i)) {
                std::cout << "cudaMemcpy(buffers[" << i << "], hostData, inputSize, cudaMemcpyHostToDevice);" << std::endl;
                break;
            }
        }
        
        // Run inference
        std::cout << "\n// 3. Run inference" << std::endl;
        if (engine->hasImplicitBatchDimension()) {
            std::cout << "context->execute(1, buffers); // batchSize = 1" << std::endl;
        } else {
            std::cout << "context->executeV2(buffers);" << std::endl;
        }
        
        // Copy output
        std::cout << "\n// 4. Copy output from GPU" << std::endl;
        for (int i = 0; i < engine->getNbBindings(); i++) {
            if (!engine->bindingIsInput(i)) {
                std::cout << "cudaMemcpy(hostOutput, buffers[" << i << "], outputSize, cudaMemcpyDeviceToHost);" << std::endl;
                break;
            }
        }
        
        // Cleanup
        std::cout << "\n// 5. Cleanup" << std::endl;
        std::cout << "for (int i = 0; i < " << engine->getNbBindings() << "; i++) {" << std::endl;
        std::cout << "    cudaFree(buffers[i]);" << std::endl;
        std::cout << "}" << std::endl;
    }
};

int main() {
    std::cout << "YOLOv12x Engine Validator" << std::endl;
    std::cout << "=========================" << std::endl;
    
    YOLOValidator validator;
    
    // Load engine
    std::cout << "Loading engine: " << ENGINE_PATH << std::endl;
    if (!validator.loadEngine(ENGINE_PATH)) {
        std::cout << "\nFAILED! Check your ENGINE_PATH in the code." << std::endl;
        return 1;
    }
    
    // Analyze engine
    validator.analyzeEngine();
    
    // Check image if path is provided
    if (!IMAGE_PATH.empty()) {
        std::cout << "\nChecking image: " << IMAGE_PATH << std::endl;
        validator.checkImage(IMAGE_PATH);
    }
    
    // Show inference code
    validator.showInferenceCode();
    
    std::cout << "\nDONE! Your engine is ready for inference." << std::endl;
    std::cout << "\nTo change files, edit ENGINE_PATH and IMAGE_PATH at the top of this code." << std::endl;
    
    return 0;
}