#include <iostream>
#include <fstream>
#include <vector>
#include <string>
#include <memory>
#include <algorithm>
#include <cmath>
#include <NvInfer.h>
#include <NvInferRuntime.h>
#include <opencv2/opencv.hpp>

class Logger : public nvinfer1::ILogger {
public:
    void log(Severity severity, const char* msg) noexcept override {
        if (severity <= Severity::kWARNING) {
            std::cout << "[TensorRT] " << msg << std::endl;
        }
    }
};

class YOLOv12xValidator {
private:
    std::unique_ptr<nvinfer1::IRuntime> runtime;
    std::unique_ptr<nvinfer1::ICudaEngine> engine;
    std::unique_ptr<nvinfer1::IExecutionContext> context;
    Logger logger;
    
    struct TensorInfo {
        std::string name;
        nvinfer1::Dims dims;
        nvinfer1::DataType dataType;
        bool isInput;
        size_t size;
    };
    
    std::vector<TensorInfo> tensors;

public:
    YOLOv12xValidator() {
        runtime = std::unique_ptr<nvinfer1::IRuntime>(nvinfer1::createInferRuntime(logger));
        if (!runtime) {
            throw std::runtime_error("Failed to create TensorRT runtime");
        }
    }
    
    bool loadEngine(const std::string& enginePath) {
        std::ifstream file(enginePath, std::ios::binary);
        if (!file.good()) {
            std::cerr << "Error: Cannot open engine file: " << enginePath << std::endl;
            return false;
        }
        
        // Get file size
        file.seekg(0, std::ios::end);
        size_t size = file.tellg();
        file.seekg(0, std::ios::beg);
        
        // Read engine data
        std::vector<char> engineData(size);
        file.read(engineData.data(), size);
        file.close();
        
        // Deserialize engine
        engine = std::unique_ptr<nvinfer1::ICudaEngine>(
            runtime->deserializeCudaEngine(engineData.data(), size));
        
        if (!engine) {
            std::cerr << "Error: Failed to deserialize engine" << std::endl;
            return false;
        }
        
        context = std::unique_ptr<nvinfer1::IExecutionContext>(engine->createExecutionContext());
        if (!context) {
            std::cerr << "Error: Failed to create execution context" << std::endl;
            return false;
        }
        
        std::cout << "✓ Engine loaded successfully: " << enginePath << std::endl;
        return true;
    }
    
    void analyzeEngine() {
        if (!engine) {
            std::cerr << "Error: Engine not loaded" << std::endl;
            return;
        }
        
        std::cout << "\n=== Engine Analysis ===" << std::endl;
        std::cout << "Engine name: " << engine->getName() << std::endl;
        
        // Use modern API - getNbIOTensors instead of getNbBindings
        int32_t nbIOTensors = engine->getNbIOTensors();
        std::cout << "Number of I/O tensors: " << nbIOTensors << std::endl;
        
        // Memory information using V2 APIs
        std::cout << "Device memory required: " << engine->getDeviceMemorySizeV2() << " bytes" << std::endl;
        std::cout << "Number of layers: " << engine->getNbLayers() << std::endl;
        
        // Clear previous analysis
        tensors.clear();
        
        // Analyze each tensor using modern API
        for (int32_t i = 0; i < nbIOTensors; ++i) {
            const char* name = engine->getIOTensorName(i);
            nvinfer1::Dims dims = engine->getTensorShape(name);
            nvinfer1::DataType dataType = engine->getTensorDataType(name);
            nvinfer1::TensorIOMode ioMode = engine->getTensorIOMode(name);
            bool isInput = (ioMode == nvinfer1::TensorIOMode::kINPUT);
            
            size_t elementCount = 1;
            for (int j = 0; j < dims.nbDims; ++j) {
                elementCount *= dims.d[j];
            }
            
            // Calculate size in bytes based on data type
            size_t elementSize = 0;
            switch (dataType) {
                case nvinfer1::DataType::kFLOAT: elementSize = 4; break;
                case nvinfer1::DataType::kHALF: elementSize = 2; break;
                case nvinfer1::DataType::kINT8: elementSize = 1; break;
                case nvinfer1::DataType::kINT32: elementSize = 4; break;
                case nvinfer1::DataType::kBOOL: elementSize = 1; break;
                case nvinfer1::DataType::kUINT8: elementSize = 1; break;
                case nvinfer1::DataType::kFP8: elementSize = 1; break;
                case nvinfer1::DataType::kBF16: elementSize = 2; break;
                case nvinfer1::DataType::kINT64: elementSize = 8; break;
                default: elementSize = 4; break;
            }
            size_t totalSize = elementCount * elementSize;
            
            std::cout << "\nTensor " << i << " (" << (isInput ? "INPUT" : "OUTPUT") << "):" << std::endl;
            std::cout << "  Name: " << name << std::endl;
            std::cout << "  Dimensions: ";
            for (int j = 0; j < dims.nbDims; ++j) {
                std::cout << dims.d[j];
                if (j < dims.nbDims - 1) std::cout << "x";
            }
            std::cout << std::endl;
            std::cout << "  Data type: " << getDataTypeName(dataType) << std::endl;
            std::cout << "  Size: " << totalSize << " bytes (" << totalSize / 1024.0 / 1024.0 << " MB)" << std::endl;
            
            tensors.push_back({name, dims, dataType, isInput, totalSize});
        }
    }
    
    std::string getDataTypeName(nvinfer1::DataType dataType) {
        switch (dataType) {
            case nvinfer1::DataType::kFLOAT: return "FLOAT32";
            case nvinfer1::DataType::kHALF: return "FLOAT16";
            case nvinfer1::DataType::kINT8: return "INT8";
            case nvinfer1::DataType::kINT32: return "INT32";
            case nvinfer1::DataType::kBOOL: return "BOOL";
            case nvinfer1::DataType::kUINT8: return "UINT8";
            case nvinfer1::DataType::kFP8: return "FP8";
            case nvinfer1::DataType::kBF16: return "BFLOAT16";
            case nvinfer1::DataType::kINT64: return "INT64";
            default: return "UNKNOWN";
        }
    }
    
    void printInputRequirements() {
        std::vector<TensorInfo> inputs;
        for (const auto& tensor : tensors) {
            if (tensor.isInput) {
                inputs.push_back(tensor);
            }
        }
        
        if (inputs.empty()) {
            std::cout << "\nNo input tensors found!" << std::endl;
            return;
        }
        
        std::cout << "\n=== Input Requirements ===" << std::endl;
        
        for (const auto& input : inputs) {
            std::cout << "\nInput: " << input.name << std::endl;
            
            if (input.dims.nbDims == 4) {  // Typical YOLO input: [batch, channels, height, width]
                int batch = input.dims.d[0];
                int channels = input.dims.d[1];
                int height = input.dims.d[2];
                int width = input.dims.d[3];
                
                std::cout << "  Batch size: " << batch << std::endl;
                std::cout << "  Channels: " << channels << std::endl;
                std::cout << "  Input size: " << height << "x" << width << std::endl;
                std::cout << "  Expected format: ";
                if (channels == 3) {
                    std::cout << "RGB" << std::endl;
                } else if (channels == 1) {
                    std::cout << "Grayscale" << std::endl;
                } else {
                    std::cout << "Unknown (" << channels << " channels)" << std::endl;
                }
                
                // Check for dynamic shapes
                if (batch == -1) {
                    std::cout << "  Dynamic batch size detected" << std::endl;
                }
                if (height == -1 || width == -1) {
                    std::cout << "  Dynamic input dimensions detected" << std::endl;
                }
            } else {
                std::cout << "  Unexpected input dimensions (ndims=" << input.dims.nbDims << ")!" << std::endl;
                std::cout << "  Shape: ";
                for (int j = 0; j < input.dims.nbDims; ++j) {
                    std::cout << input.dims.d[j];
                    if (j < input.dims.nbDims - 1) std::cout << "x";
                }
                std::cout << std::endl;
            }
        }
    }
    
    struct PaddingInfo {
        int top, bottom, left, right;
        float scale;
        int newWidth, newHeight;
        cv::Scalar paddingColor;
    };
    
    PaddingInfo calculatePadding(int imgWidth, int imgHeight, int targetWidth, int targetHeight, 
                                bool maintainAspectRatio = true) {
        PaddingInfo padding = {0, 0, 0, 0, 1.0f, targetWidth, targetHeight, cv::Scalar(114, 114, 114)};
        
        if (!maintainAspectRatio) {
            // Simple resize without maintaining aspect ratio
            padding.scale = std::min(static_cast<float>(targetWidth) / imgWidth, 
                                   static_cast<float>(targetHeight) / imgHeight);
            return padding;
        }
        
        // Calculate scale to fit image within target size while maintaining aspect ratio
        float scaleX = static_cast<float>(targetWidth) / imgWidth;
        float scaleY = static_cast<float>(targetHeight) / imgHeight;
        float scale = std::min(scaleX, scaleY);
        
        padding.scale = scale;
        
        // Calculate new dimensions after scaling
        int newWidth = static_cast<int>(imgWidth * scale);
        int newHeight = static_cast<int>(imgHeight * scale);
        
        padding.newWidth = newWidth;
        padding.newHeight = newHeight;
        
        // Calculate padding to center the image
        int padX = (targetWidth - newWidth) / 2;
        int padY = (targetHeight - newHeight) / 2;
        
        padding.left = padX;
        padding.right = targetWidth - newWidth - padX;
        padding.top = padY;
        padding.bottom = targetHeight - newHeight - padY;
        
        return padding;
    }
    
    void checkImageCompatibility(const std::string& imagePath) {
        std::vector<TensorInfo> inputs;
        for (const auto& tensor : tensors) {
            if (tensor.isInput) {
                inputs.push_back(tensor);
            }
        }
        
        if (inputs.empty()) {
            std::cout << "\nNo input information available. Run analyzeEngine() first." << std::endl;
            return;
        }
        
        // Load image
        cv::Mat image = cv::imread(imagePath);
        if (image.empty()) {
            std::cerr << "Error: Cannot load image: " << imagePath << std::endl;
            return;
        }
        
        std::cout << "\n=== Image Compatibility Check ===" << std::endl;
        std::cout << "Image: " << imagePath << std::endl;
        std::cout << "Image size: " << image.cols << "x" << image.rows << std::endl;
        std::cout << "Image channels: " << image.channels() << std::endl;
        std::cout << "Image depth: " << image.depth() << " (CV_8U=" << CV_8U << ", CV_32F=" << CV_32F << ")" << std::endl;
        
        // Check against first input (assuming it's the main input)
        const auto& input = inputs[0];
        if (input.dims.nbDims == 4) {
            int targetBatch = input.dims.d[0];
            int targetChannels = input.dims.d[1];
            int targetHeight = input.dims.d[2];
            int targetWidth = input.dims.d[3];
            
            std::cout << "Required batch: " << targetBatch << std::endl;
            std::cout << "Required size: " << targetWidth << "x" << targetHeight << std::endl;
            std::cout << "Required channels: " << targetChannels << std::endl;
            
            // Check for dynamic dimensions
            if (targetBatch == -1) {
                std::cout << "✓ Dynamic batch size - any batch size supported" << std::endl;
            }
            if (targetHeight == -1 || targetWidth == -1) {
                std::cout << "✓ Dynamic input size - various sizes supported" << std::endl;
                std::cout << "  Note: You'll need to set tensor shapes at runtime using setInputShape()" << std::endl;
            }
            
            // Check channel compatibility
            if (image.channels() != targetChannels && targetChannels != -1) {
                std::cout << "⚠ Channel mismatch! Image has " << image.channels() 
                         << " channels, model expects " << targetChannels << std::endl;
                if (targetChannels == 3 && image.channels() == 1) {
                    std::cout << "  → Convert grayscale to RGB using cv::cvtColor(img, img, cv::COLOR_GRAY2RGB)" << std::endl;
                } else if (targetChannels == 1 && image.channels() == 3) {
                    std::cout << "  → Convert RGB to grayscale using cv::cvtColor(img, img, cv::COLOR_RGB2GRAY)" << std::endl;
                }
            } else {
                std::cout << "✓ Channel compatibility OK" << std::endl;
            }
            
            // Calculate padding only for fixed sizes
            if (targetHeight > 0 && targetWidth > 0) {
                PaddingInfo padding = calculatePadding(image.cols, image.rows, targetWidth, targetHeight);
                
                std::cout << "\n=== Preprocessing Requirements ===" << std::endl;
                std::cout << "Scale factor: " << padding.scale << std::endl;
                std::cout << "Scaled size: " << padding.newWidth << "x" << padding.newHeight << std::endl;
                std::cout << "Padding (LTRB): " << padding.left << ", " << padding.top 
                         << ", " << padding.right << ", " << padding.bottom << std::endl;
                
                if (padding.left > 0 || padding.right > 0 || padding.top > 0 || padding.bottom > 0) {
                    std::cout << "Padding color: [114, 114, 114] (gray)" << std::endl;
                    std::cout << "OpenCV padding call:" << std::endl;
                    std::cout << "  cv::copyMakeBorder(resized, padded, " << padding.top << ", " 
                             << padding.bottom << ", " << padding.left << ", " << padding.right 
                             << ", cv::BORDER_CONSTANT, cv::Scalar(114, 114, 114));" << std::endl;
                }
                
                // Data type conversion info
                std::cout << "\nData conversion:" << std::endl;
                std::cout << "  1. Convert to float: image.convertTo(floatImg, CV_32F, 1.0/255.0)" << std::endl;
                std::cout << "  2. Normalize if needed (depends on training)" << std::endl;
                std::cout << "  3. Convert HWC to CHW format" << std::endl;
                std::cout << "  4. Copy to GPU memory" << std::endl;
            }
        }
    }
    
    void printMemoryRequirements() {
        if (tensors.empty()) {
            std::cout << "\nNo tensor information available." << std::endl;
            return;
        }
        
        std::cout << "\n=== Memory Requirements ===" << std::endl;
        
        size_t totalInputSize = 0;
        size_t totalOutputSize = 0;
        
        for (const auto& tensor : tensors) {
            if (tensor.isInput) {
                totalInputSize += tensor.size;
                std::cout << "Input buffer (" << tensor.name << "): " << tensor.size 
                         << " bytes (" << tensor.size / 1024.0 / 1024.0 << " MB)" << std::endl;
            } else {
                totalOutputSize += tensor.size;
                std::cout << "Output buffer (" << tensor.name << "): " << tensor.size 
                         << " bytes (" << tensor.size / 1024.0 / 1024.0 << " MB)" << std::endl;
            }
        }
        
        size_t totalIOSize = totalInputSize + totalOutputSize;
        size_t deviceMemory = engine->getDeviceMemorySizeV2();
        
        std::cout << "Total I/O memory: " << totalIOSize << " bytes (" 
                 << totalIOSize / 1024.0 / 1024.0 << " MB)" << std::endl;
        std::cout << "Device memory: " << deviceMemory << " bytes ("
                 << deviceMemory / 1024.0 / 1024.0 << " MB)" << std::endl;
        std::cout << "Total GPU memory needed: " << (totalIOSize + deviceMemory) << " bytes ("
                 << (totalIOSize + deviceMemory) / 1024.0 / 1024.0 << " MB)" << std::endl;
    }
    
    bool validateEngine() {
        if (!engine || !context) {
            std::cerr << "Engine not properly loaded" << std::endl;
            return false;
        }
        
        std::cout << "\n=== Engine Validation ===" << std::endl;
        
        // Check if engine has tensors
        int32_t nbIOTensors = engine->getNbIOTensors();
        if (nbIOTensors == 0) {
            std::cerr << "✗ Engine has no I/O tensors" << std::endl;
            return false;
        }
        
        // Check for typical YOLO structure
        bool hasInput = false;
        bool hasOutput = false;
        
        for (int32_t i = 0; i < nbIOTensors; ++i) {
            const char* name = engine->getIOTensorName(i);
            nvinfer1::TensorIOMode ioMode = engine->getTensorIOMode(name);
            
            if (ioMode == nvinfer1::TensorIOMode::kINPUT) {
                hasInput = true;
            } else if (ioMode == nvinfer1::TensorIOMode::kOUTPUT) {
                hasOutput = true;
            }
        }
        
        if (!hasInput) {
            std::cerr << "✗ No input tensors found" << std::endl;
            return false;
        }
        
        if (!hasOutput) {
            std::cerr << "✗ No output tensors found" << std::endl;
            return false;
        }
        
        std::cout << "✓ Engine structure valid" << std::endl;
        std::cout << "✓ Input/output tensors present" << std::endl;
        
        // Check if this looks like a YOLO model
        bool looksLikeYOLO = false;
        for (const auto& tensor : tensors) {
            if (tensor.isInput && tensor.dims.nbDims == 4) {
                // Typical YOLO input: [batch, 3, height, width]
                if (tensor.dims.d[1] == 3) {
                    looksLikeYOLO = true;
                    break;
                }
            }
        }
        
        if (looksLikeYOLO) {
            std::cout << "✓ Appears to be a YOLO-compatible model" << std::endl;
        } else {
            std::cout << "⚠ May not be a standard YOLO model format" << std::endl;
        }
        
        return true;
    }
    
    void printAdvancedInfo() {
        std::cout << "\n=== Advanced Engine Information ===" << std::endl;
        std::cout << "Engine capability: ";
        nvinfer1::EngineCapability capability = engine->getEngineCapability();
        switch (capability) {
            case nvinfer1::EngineCapability::kSTANDARD:
                std::cout << "STANDARD (full functionality)" << std::endl;
                break;
            case nvinfer1::EngineCapability::kSAFETY:
                std::cout << "SAFETY (limited functionality)" << std::endl;
                break;
            default:
                std::cout << "Unknown" << std::endl;
                break;
        }
        
        std::cout << "Number of auxiliary streams: " << engine->getNbAuxStreams() << std::endl;
        std::cout << "Streamable weights size: " << engine->getStreamableWeightsSize() 
                 << " bytes (" << engine->getStreamableWeightsSize() / 1024.0 / 1024.0 << " MB)" << std::endl;
        
        // Check if engine can be refitted
        if (engine->isRefittable()) {
            std::cout << "✓ Engine supports weight refitting" << std::endl;
        } else {
            std::cout << "Engine does not support weight refitting" << std::endl;
        }
        
        std::cout << "\nTensor Details:" << std::endl;
        for (const auto& tensor : tensors) {
            std::cout << "  " << tensor.name << ": ";
            if (engine->isShapeInferenceIO(tensor.name.c_str())) {
                std::cout << "Shape inference tensor";
            } else {
                std::cout << "Regular tensor";
            }
            std::cout << std::endl;
        }
    }
};

int main(int argc, char* argv[]) {
    if (argc < 2) {
        std::cerr << "Usage: " << argv[0] << " <engine_file> [image_file]" << std::endl;
        std::cerr << "Example: " << argv[0] << " yolov12x.plan test_image.jpg" << std::endl;
        return 1;
    }
    
    std::string enginePath = argv[1];
    std::string imagePath = (argc > 2) ? argv[2] : "";
    
    try {
        YOLOv12xValidator validator;
        
        // Load and validate engine
        if (!validator.loadEngine(enginePath)) {
            return 1;
        }
        
        if (!validator.validateEngine()) {
            return 1;
        }
        
        // Analyze engine structure
        validator.analyzeEngine();
        validator.printInputRequirements();
        validator.printMemoryRequirements();
        validator.printAdvancedInfo();
        
        // Check image compatibility if provided
        if (!imagePath.empty()) {
            validator.checkImageCompatibility(imagePath);
        } else {
            std::cout << "\n=== Image Testing ===" << std::endl;
            std::cout << "To test image compatibility, run:" << std::endl;
            std::cout << argv[0] << " " << enginePath << " <image_file>" << std::endl;
        }
        
        std::cout << "\n✓ Engine validation complete!" << std::endl;
        std::cout << "\nNext steps for inference:" << std::endl;
        std::cout << "1. Allocate GPU memory for input/output tensors" << std::endl;
        std::cout << "2. Preprocess images (resize, pad, normalize, HWC→CHW)" << std::endl;
        std::cout << "3. Copy input data to GPU" << std::endl;
        std::cout << "4. Run inference using context->executeV2()" << std::endl;
        std::cout << "5. Copy output data from GPU and post-process" << std::endl;
        
    } catch (const std::exception& e) {
        std::cerr << "Error: " << e.what() << std::endl;
        return 1;
    }
    
    return 0;
}